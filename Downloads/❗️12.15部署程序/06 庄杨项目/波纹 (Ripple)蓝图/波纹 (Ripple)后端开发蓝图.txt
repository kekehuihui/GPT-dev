这篇文档将作为“波纹 (Ripple)”后端开发的**核心蓝图**。我们将应用所需的数据拆解为 **4 大类**，并为每一类数据提供**“低成本 MVP 方案”**和**“商业化进阶方案”**。

---

### 📊 波纹 (Ripple) 数据需求架构图

我们将数据分为：**基础行情**（骨架）、**舆情文本**（血肉）、**资金流向**（脉搏）、**事件日历**（神经）。

---

### 第一类：基础行情数据 (Market Data)

*这是最基础的“骨架”，用于绘制 K 线图、计算涨跌幅、同步交易时间。*

#### 1. 需要哪些字段？

* **实时数据 (Tick/Snapshot)**：最新价、涨跌幅、成交量、成交额、五档买卖盘（Bid/Ask）。
* **历史数据 (History)**：过去 1-3 年的日 K 线（用于回测）、过去 5 天的分时数据（分钟级）。
* **基础信息 (Meta)**：股票名称、代码、总市值、流通市值、行业分类。

#### 2. 怎么解决？

* **方案 A (免费/开源 - 推荐 MVP 使用)**：
* **工具**：**[AkShare](https://github.com/akfamily/akshare)** (Python 库)。
* **原理**：它封装了新浪财经、东方财富、腾讯财经的公开接口。
* **代码示例**：
```python
import akshare as ak
# 获取个股实时行情
df = ak.stock_zh_a_spot_em() 
# 获取某只股票的历史 K 线
hist = ak.stock_zh_a_hist(symbol="600519", period="daily")

```




* **方案 B (稳定/低费 - 进阶推荐)**：
* **工具**：**Tushare Pro**。
* **特点**：数据更规范，有积分制，基础数据免费，高频数据只需几百元/年，适合初创团队。



---

### 第二类：舆情文本数据 (Sentiment Data)

*这是波纹的核心“血肉”，也就是 AI 分析的原材料。*

#### 1. 需要哪些字段？

* **来源 (Source)**：是来自股吧、雪球、微博还是新闻联播？
* **内容 (Content)**：标题、正文摘要。
* **时间 (Timestamp)**：**精确到秒**。这非常关键，因为我们需要对比“舆情发生时间”和“股价异动时间”的先后关系。
* **热度指标 (Meta)**：阅读量、评论数、点赞数（用于计算权重）。
* **作者 (Author)**：判断是“散户”、“大V”还是“官方媒体”。

#### 2. 怎么解决？

*这部分没有现成的 API，必须自己写爬虫 (Crawler)。*

* **目标 1：高频散户情绪 (Noise)**
* **目标站**：**东方财富股吧** (guba.eastmoney.com)。
* **方法**：编写 Python 脚本，每 30 秒扫描一次个股的“最新评论”列表。


* **目标 2：专业深度观点 (Logic)**
* **目标站**：**雪球** (xueqiu.com)。
* **方法**：重点抓取“热门”栏目，关注大V的长文。


* **目标 3：突发利好/利空 (News)**
* **目标站**：**财联社电报** (cls.cn/telegraph)。
* **方法**：监控 7x24 小时电报流，这是目前 A 股游资反应最快的信息源。



---

### 第三类：深度资金数据 (Smart Money Flow)

*这是市场的“脉搏”，用来验证舆情是否转化为真实的买卖。*

#### 1. 需要哪些字段？

* **主力净流入 (Net Inflow)**：超大单 + 大单的净买入额。
* **散户净流入**：中单 + 小单的净买入额。
* **量比/换手率**：判断筹码交换的激烈程度。
* **（进阶）逐笔成交 (Level-2)**：每一笔交易是主动买入还是主动卖出。

#### 2. 怎么解决？

* **方案 A (免费/估算)**：
* **工具**：**AkShare** (东方财富接口)。
* **局限**：东财的数据是基于 Level-1 估算的，虽然不是 100% 精确的 Level-2，但用来做“趋势判断”已经足够。
* **获取**：`ak.stock_individual_fund_flow(stock="600519")`。


* **方案 B (付费/精确)**：
* 购买券商或数据商的 **Level-2 数据接口**。成本较高（通常 5000元+/年），建议有了用户基础后再接入。



---

### 第四类：事件与日历数据 (Event Radar)

*这是“事件雷达”功能的基础。*

#### 1. 需要哪些字段？

* **财报日历**：预约披露日期。
* **宏观日历**：美联储议息会议日期、中国 GDP/CPI 发布日期。
* **行业会议**：世界人工智能大会、车展、苹果发布会等日期。
* **停复牌信息**。

#### 2. 怎么解决？

* **财报/宏观**：AkShare 均有提供（数据源来自新浪财经数据中心）。
* **行业会议**：这部分比较难自动化。
* **初期**：**人工维护**。每天花 10 分钟收集核心会议录入数据库。
* **后期**：利用 **Gemini** 分析财经新闻，让 AI 自动提取新闻中的“未来时间点”和“事件名称”，存入数据库。



---

### 💡 核心：这四类数据如何“炼金”？

您并不只是把这些数据展示出来，而是要通过后端处理，生成**衍生数据 (Derived Data)**：

1. **清洗 (ETL)**：爬虫抓回来的数据很脏（如“加微信带炒股”的广告），先用规则清洗掉。
2. **打分 (NLP)**：
* `Raw Text` (爬虫数据) -> **Gemini API** -> `Sentiment Score` (-1 到 1)。


3. **聚合 (Aggregation)**：
* `Sentiment Score` + `Volume` (成交量) -> **舆情 Alpha 指数**。



### 🗺️ 行动清单 (Action Plan)

建议您按照以下顺序开始搜集数据：

1. **Day 1**: 用 Python `pip install akshare`，先跑通**茅台的实时股价**获取。
2. **Day 2**: 写一个简单的 `requests` 脚本，抓取**东方财富股吧**某一页的标题，打印在控制台。
3. **Day 3**: 申请 Google Gemini API Key，把抓到的标题发给 AI，让它判断是利好还是利空。

只要打通了这三步，您的波纹系统就有了灵魂。